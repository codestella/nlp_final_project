rene
./result/large_tanh_linear_0.0001_p0.1
Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Parameters of encoder are fixed!
[Epoch 0] Train loss: 0.140, acc: 0.50, time: 103.0s
[Epoch 0] Valid loss: 0.138, acc: 0.54
[Epoch 1] Train loss: 0.140, acc: 0.52, time: 104.4s
[Epoch 1] Valid loss: 0.137, acc: 0.55
[Epoch 2] Train loss: 0.140, acc: 0.53, time: 105.5s
[Epoch 2] Valid loss: 0.143, acc: 0.54
[Epoch 3] Train loss: 0.138, acc: 0.55, time: 112.7s
[Epoch 3] Valid loss: 0.138, acc: 0.54
[Epoch 4] Train loss: 0.138, acc: 0.55, time: 113.3s
[Epoch 4] Valid loss: 0.140, acc: 0.54
[Epoch 5] Train loss: 0.137, acc: 0.55, time: 114.4s
[Epoch 5] Valid loss: 0.140, acc: 0.54
[Epoch 6] Train loss: 0.137, acc: 0.55, time: 114.6s
[Epoch 6] Valid loss: 0.149, acc: 0.47
[Epoch 7] Train loss: 0.137, acc: 0.55, time: 114.9s
[Epoch 7] Valid loss: 0.137, acc: 0.54
[Epoch 8] Train loss: 0.137, acc: 0.55, time: 115.3s
[Epoch 8] Valid loss: 0.137, acc: 0.58
[Epoch 9] Train loss: 0.137, acc: 0.55, time: 110.3s
[Epoch 9] Valid loss: 0.142, acc: 0.49
[Epoch 10] Train loss: 0.136, acc: 0.57, time: 114.3s
[Epoch 10] Valid loss: 0.137, acc: 0.57
[Epoch 11] Train loss: 0.136, acc: 0.57, time: 114.5s
[Epoch 11] Valid loss: 0.138, acc: 0.51
[Epoch 12] Train loss: 0.135, acc: 0.57, time: 113.9s
[Epoch 12] Valid loss: 0.138, acc: 0.51
[Epoch 13] Train loss: 0.135, acc: 0.58, time: 113.9s
[Epoch 13] Valid loss: 0.137, acc: 0.55
[Epoch 14] Train loss: 0.135, acc: 0.58, time: 113.5s
[Epoch 14] Valid loss: 0.139, acc: 0.49
[Epoch 15] Train loss: 0.135, acc: 0.58, time: 113.4s
[Epoch 15] Valid loss: 0.137, acc: 0.57
[Epoch 16] Train loss: 0.135, acc: 0.58, time: 112.8s
[Epoch 16] Valid loss: 0.145, acc: 0.50
[Epoch 17] Train loss: 0.135, acc: 0.58, time: 113.2s
[Epoch 17] Valid loss: 0.136, acc: 0.57
[Epoch 18] Train loss: 0.134, acc: 0.58, time: 113.1s
[Epoch 18] Valid loss: 0.138, acc: 0.51
[Epoch 19] Train loss: 0.135, acc: 0.58, time: 112.9s
[Epoch 19] Valid loss: 0.139, acc: 0.50
[Epoch 20] Train loss: 0.134, acc: 0.59, time: 113.2s
[Epoch 20] Valid loss: 0.139, acc: 0.49
[Epoch 21] Train loss: 0.135, acc: 0.58, time: 113.4s
[Epoch 21] Valid loss: 0.136, acc: 0.57
[Epoch 22] Train loss: 0.135, acc: 0.58, time: 112.9s
[Epoch 22] Valid loss: 0.137, acc: 0.51
[Epoch 23] Train loss: 0.135, acc: 0.58, time: 112.9s
[Epoch 23] Valid loss: 0.136, acc: 0.58
[Epoch 24] Train loss: 0.134, acc: 0.58, time: 113.2s
[Epoch 24] Valid loss: 0.137, acc: 0.56
[Epoch 25] Train loss: 0.134, acc: 0.58, time: 113.0s
[Epoch 25] Valid loss: 0.139, acc: 0.50
[Epoch 26] Train loss: 0.134, acc: 0.59, time: 112.9s
[Epoch 26] Valid loss: 0.136, acc: 0.58
[Epoch 27] Train loss: 0.134, acc: 0.58, time: 108.8s
[Epoch 27] Valid loss: 0.136, acc: 0.58
[Epoch 28] Train loss: 0.133, acc: 0.59, time: 108.4s
[Epoch 28] Valid loss: 0.136, acc: 0.57
[Epoch 29] Train loss: 0.133, acc: 0.59, time: 112.9s
[Epoch 29] Valid loss: 0.136, acc: 0.56
hostname : rene, partition : titan, script : ~/anaconda3/envs/10/bin/python -u main.py  --tune linear --size large --lr 0.0001
